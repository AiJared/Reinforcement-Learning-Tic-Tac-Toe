{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc951f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d271ca",
   "metadata": {},
   "source": [
    "## Define the Tic Tac Toe Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "414862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rows and columns\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28709b",
   "metadata": {},
   "source": [
    "## Function for the different states that we can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e1e19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        # init p1 plays first\n",
    "        self.playerSymbol = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2e2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique hash of the current board state\n",
    "def getHash(self):\n",
    "    self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "    return self.boardHash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a6441f",
   "metadata": {},
   "source": [
    "## Function to get the winner of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cfc236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(self):\n",
    "    # row\n",
    "    for i in range(BOARD_ROWS):\n",
    "        if sum(self.board[i, :]) == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if sum(self.board[i, :]) == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "    # col\n",
    "    for i in range(BOARD_COLS):\n",
    "        if sum(self.board[:, i]) == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if sum(self.board[:, i]) == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "    # diagonal\n",
    "    diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "    diag_sum2 = sum([self.board[i, BOARD_COLS--i-1] for i in range(BOARD_COLS)])\n",
    "    if diag_sum == 3:\n",
    "        self.isEnd = True\n",
    "        return 1\n",
    "    if diag_sum == -3:\n",
    "        self.isEnd = True\n",
    "        retirn -1\n",
    "    \n",
    "    # tie\n",
    "    # no available positions\n",
    "    if len(self.availablePositions()) == 0:\n",
    "        self.isEnd = True\n",
    "        return 0\n",
    "    # not end\n",
    "    self.isEnd = False\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f101c36",
   "metadata": {},
   "source": [
    "Let's define a function to keep track of the available positions on the board. We will also define a function to update the state and a reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2102984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def availablePositions(self):\n",
    "    positions = []\n",
    "    for i in range(BOARD_ROWS):\n",
    "        for j in range(BOARD_COLS):\n",
    "            if self.board[i, j] == 0:\n",
    "                positions.append((i, j)) # need to be tuple\n",
    "    return positions\n",
    "\n",
    "def updateState(self, position):\n",
    "    self.board[position] = self.playerSymbol\n",
    "    # switch to another player\n",
    "    self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "    \n",
    "# only when game ends\n",
    "def giveRewards(self):\n",
    "    result = self.winner()\n",
    "    # backpropagate reward\n",
    "    if result == 1:\n",
    "        self.p1.feedReward(1)\n",
    "        self.p2.feedReward(0)\n",
    "    elif result == -1:\n",
    "        self.p1.feedReward(0)\n",
    "        self.p2.feedReward(1)\n",
    "    else:\n",
    "        self.p1.feedReward(0.1)\n",
    "        self.p2.feedReward(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031965ce",
   "metadata": {},
   "source": [
    "After the game is over, we need to reset the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33dbb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# board reset\n",
    "def reset(self):\n",
    "    self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "    self.boardHash = None\n",
    "    self.isEnd = False\n",
    "    self.playerSymbol = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc823a",
   "metadata": {},
   "source": [
    "Let us define the main paly function between two opponents we will use to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da1a8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(self, rounds=100):\n",
    "    for i in range(rounds):\n",
    "        if i%100 == 0:\n",
    "            print(\"Rounds {}\".format(i))\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # take action and update board state\n",
    "            self.updateState(p1_action)\n",
    "            boad_hash = self.getHash()\n",
    "            self.p1.addState(board_hash)\n",
    "            # check board status if it is end\n",
    "            \n",
    "            win = selg.winner()\n",
    "            if win is not None:\n",
    "                # self.ShowBoard()\n",
    "                # ended with p1 either win or draw\n",
    "                self.giveReward()\n",
    "                self.p1.reset()\n",
    "                self.p2.reset()\n",
    "                self.reset()\n",
    "                break\n",
    "        else:\n",
    "            # Player 2\n",
    "            postions = self.availablePositions()\n",
    "            p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            self.updateState(p2_action)\n",
    "            board_hash = self.getHash()\n",
    "            self.p2.addState(board_hash)\n",
    "            \n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                # self.showBoard()\n",
    "                # ended with p2 either win or draw\n",
    "                self.giveReward()\n",
    "                self.p1.reset()\n",
    "                self.p2.reset()\n",
    "                self.reset()\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab96bd",
   "metadata": {},
   "source": [
    "We now define a function to play the actual game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1ffcf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with human\n",
    "def play2(self):\n",
    "    while not self.isEnd():\n",
    "        # Player 1\n",
    "        positions = self.availablePositions()\n",
    "        p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "        # take action and update board state\n",
    "        self.updateState(p1_action)\n",
    "        self.showBoard()\n",
    "        # show board status of it is end\n",
    "        win = self.winner()\n",
    "        if win is not None:\n",
    "            if win == 1:\n",
    "                print(self.p1.name, \"wins!\")\n",
    "            else:\n",
    "                print(\"tie!\")\n",
    "            self.reset()\n",
    "            break\n",
    "        else:\n",
    "            # Player 2\n",
    "            positions = self.availablePositions()\n",
    "            p2_action = self.p2.chooseAction(positions)\n",
    "\n",
    "            self.updateState(p2_action)\n",
    "            self.showBoard()\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win  == -1:\n",
    "                    print(self.p2.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d2eff",
   "metadata": {},
   "source": [
    "### Function to draw a board on the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a5541b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBoard(self):\n",
    "    # p1: x p2: o\n",
    "    for i in range(0, BOARD_ROWS):\n",
    "        print(\"-------------\")\n",
    "        out = \" | \"\n",
    "        for j in range(0, BOARD_COLS):\n",
    "            if self.board[i, j] == 1:\n",
    "                token = \"x\"\n",
    "            if self.board[i, j] == -1:\n",
    "                token = \"o\"\n",
    "            if self.board[i, j] == 0:\n",
    "                token = \"\"\n",
    "            out += token + ' | '\n",
    "        print(out)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce205dc",
   "metadata": {},
   "source": [
    "Let's define a player class to instantiate players and define policy. This will be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bf65287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = [] # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {} # state -> value\n",
    "        \n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return boardHash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4313b",
   "metadata": {},
   "source": [
    "Choosing actions for the player function and defining state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d4fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseAction(self, positions, current_board, symbol):\n",
    "    if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "        idx = np.random.choice(len(positions))\n",
    "        action = positions[idx]\n",
    "    else:\n",
    "        value_max = -999\n",
    "        for p in positions:\n",
    "            next_board = current_board.copy()\n",
    "            next_board[p] = symbol\n",
    "            next_boardHash = self.getHash(next_board)\n",
    "            value = 0 if self.state_value.get(next_boardHash) is None else self.state_value.get(next_boardHash)\n",
    "            # print(\"value\", value)\n",
    "            if value >= value_max:\n",
    "                value_max = value\n",
    "                action = p\n",
    "                \n",
    "    # print(\"{} takes action {}\".format(self.name, action))\n",
    "    return action\n",
    "    \n",
    "# append a hash state\n",
    "def addState(self, state):\n",
    "    self.states.append(state)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b23b1",
   "metadata": {},
   "source": [
    "#### Define the Reward function and save the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e319a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the end of game, backpropagate and update states value\n",
    "def feedReward(self, reward):\n",
    "    for st in reversed(self.states):\n",
    "        if self.states_value.get(st) is None:\n",
    "            self.sates_value[st] = 0\n",
    "        self.states_value[st] += self.lr*(self.decay_gamma*reward - self.states_value[st])\n",
    "        reward = self.states_value[st]\n",
    "    \n",
    "\n",
    "def reset(self):\n",
    "    self.states = []\n",
    "    \n",
    "def savePolicy(self):\n",
    "    fw = open(\"policy_\", +str(self.name),\"wb\")\n",
    "    pickle.dump(self.states_value, fw)\n",
    "    fw.close()\n",
    "    \n",
    "def loadPolicy(self, file):\n",
    "    fr = open(file, \"rb\")\n",
    "    self.states_value = pickle.load(fr)\n",
    "    fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4862b2",
   "metadata": {},
   "source": [
    "Now let's define a class that will be called when the player has to take an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5cb109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    \n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce12ae",
   "metadata": {},
   "source": [
    "Now let us define our machine players and train the model using the policy we made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7931db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'State' object has no attribute 'play'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m st \u001b[38;5;241m=\u001b[39m State(p1, p2)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m(\u001b[38;5;241m50000\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'State' object has no attribute 'play'"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"p1\")\n",
    "p2 = Player(\"p2\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca10aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
