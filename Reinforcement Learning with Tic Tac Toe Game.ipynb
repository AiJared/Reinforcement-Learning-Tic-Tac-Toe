{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc951f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d271ca",
   "metadata": {},
   "source": [
    "## Define the Tic Tac Toe Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rows and columns\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28709b",
   "metadata": {},
   "source": [
    "## Function for the different states that we can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e1e19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        # init p1 plays first\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    # The actions taken on the board will have to be stored as a hash function\n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "    \n",
    "    # let us define a function to find the winner of the game\n",
    "    def winner(self):\n",
    "        # row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        \n",
    "        # col\n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # diagonal\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2  = sum([self.board[i, BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(diag_sum1, diag_sum2)\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if diag_sum == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "          \n",
    "         # tie\n",
    "        # no available positions\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i,j)) # need to be tuple\n",
    "        return positions\n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        # switch to another player\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "        \n",
    "    # only when the game ends\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        # backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "    # board reset\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "    # play function between two opponents we will use to train the model\n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i%100 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # player 1\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # take action and update board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "                \n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "                else:\n",
    "                    # player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "                    \n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "    # play with human\n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            # palyer 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # take action and update board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            #check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "            else:\n",
    "                # player 2\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "                \n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "    def showBoard(self):\n",
    "        # p1: x p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = ' | '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = \"x\"\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = \"o\"\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d40e4",
   "metadata": {},
   "source": [
    "#### Player class to instantiate players and define the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e135d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = [] # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {} # state -> value\n",
    "        \n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS*BOARD_COLS))\n",
    "        return boardHash\n",
    "    \n",
    "    # choosing actions for the player function and defining state:\n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "            \n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        # print(\"{} takes action {}\".format(self.name, action))\n",
    "        return action\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    # we also define the reward function and save the policy\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr*(self.decay_gamma*reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "        \n",
    "    def savePolicy(self):\n",
    "        fw = open(\"policy_\" +str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "    \n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fef21",
   "metadata": {},
   "source": [
    "Now let's define a class that will be called when the player has to take an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41e2ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2877e",
   "metadata": {},
   "source": [
    "Let us define our machine players and train the model using the policy made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a5b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Rounds 0\n",
      "Rounds 100\n",
      "Rounds 200\n",
      "Rounds 300\n",
      "Rounds 400\n",
      "Rounds 500\n",
      "Rounds 600\n",
      "Rounds 700\n",
      "Rounds 800\n",
      "Rounds 900\n",
      "Rounds 1000\n",
      "Rounds 1100\n",
      "Rounds 1200\n",
      "Rounds 1300\n",
      "Rounds 1400\n",
      "Rounds 1500\n",
      "Rounds 1600\n",
      "Rounds 1700\n",
      "Rounds 1800\n",
      "Rounds 1900\n",
      "Rounds 2000\n",
      "Rounds 2100\n",
      "Rounds 2200\n",
      "Rounds 2300\n",
      "Rounds 2400\n",
      "Rounds 2500\n",
      "Rounds 2600\n",
      "Rounds 2700\n",
      "Rounds 2800\n",
      "Rounds 2900\n",
      "Rounds 3000\n",
      "Rounds 3100\n",
      "Rounds 3200\n",
      "Rounds 3300\n",
      "Rounds 3400\n",
      "Rounds 3500\n",
      "Rounds 3600\n",
      "Rounds 3700\n",
      "Rounds 3800\n",
      "Rounds 3900\n",
      "Rounds 4000\n",
      "Rounds 4100\n",
      "Rounds 4200\n",
      "Rounds 4300\n",
      "Rounds 4400\n",
      "Rounds 4500\n",
      "Rounds 4600\n",
      "Rounds 4700\n",
      "Rounds 4800\n",
      "Rounds 4900\n"
     ]
    }
   ],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3\n",
    "\n",
    "p1 = Player(\"p1\")\n",
    "p2 = Player(\"p2\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18004284",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.savePolicy()\n",
    "p2.savePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97a6a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.loadPolicy(\"policy_p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb32f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      " |   |   |   | \n",
      "-------------\n",
      " |   |   |   | \n",
      "-------------\n",
      " |   |   | x | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:0\n",
      "-------------\n",
      " | o |   |   | \n",
      "-------------\n",
      " |   |   |   | \n",
      "-------------\n",
      " |   |   | x | \n",
      "-------------\n",
      "-------------\n",
      " | o |   | x | \n",
      "-------------\n",
      " |   |   |   | \n",
      "-------------\n",
      " |   |   | x | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:0\n",
      "-------------\n",
      " | o |   | x | \n",
      "-------------\n",
      " |   |   |   | \n",
      "-------------\n",
      " | o |   | x | \n",
      "-------------\n",
      "-------------\n",
      " | o |   | x | \n",
      "-------------\n",
      " |   |   | x | \n",
      "-------------\n",
      " | o |   | x | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8381167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
